{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642a2d94",
   "metadata": {},
   "source": [
    "# Solution: Build a Simple NN on Fashion-MNIST\n",
    "\n",
    "This notebook implements the required Multilayer Perceptron (MLP) to classify Fashion-MNIST images. It follows the assignment instructions: two hidden layers (256, 128), ReLU activations, CrossEntropyLoss, Adam optimizer (lr=0.001), batch size 64, and 5-10 epochs.\n",
    "\n",
    "**How to use:** Run each cell in order. The notebook will download the Fashion-MNIST dataset (via torchvision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # scales to [0,1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "print('Classes:', classes)\n",
    "print('Train size:', len(train_dataset), 'Test size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4319c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition: simple MLP as required\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),            # 28*28 -> 784\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SimpleMLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation helpers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return running_loss / total, correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (set epochs between 5 and 10 as required)\n",
    "epochs = 8  # change to between 5 and 10 if desired\n",
    "train_losses, train_accs = [], []\n",
    "test_losses, test_accs = [], []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "    train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "    test_losses.append(test_loss); test_accs.append(test_acc)\n",
    "    print(f\"Epoch {epoch}/{epochs} - Train loss: {train_loss:.4f}, Train acc: {train_acc*100:.2f}% | Test loss: {test_loss:.4f}, Test acc: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: loss and accuracy over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, marker='o', label='Train Loss')\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, marker='o', label='Test Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss per epoch'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, len(train_accs)+1), [a*100 for a in train_accs], marker='o', label='Train Acc')\n",
    "plt.plot(range(1, len(test_accs)+1), [a*100 for a in test_accs], marker='o', label='Test Acc')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.title('Accuracy per epoch'); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix on test set\n",
    "test_loss, test_acc, all_preds, all_labels = evaluate(model, test_loader, criterion, device)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "plt.figure(figsize=(8,8))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', values_format='d')\n",
    "plt.title(f'Test Accuracy: {test_acc*100:.2f}%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example images: correct and incorrect predictions\n",
    "import random\n",
    "model.eval()\n",
    "examples = []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        for i in range(len(labels)):\n",
    "            examples.append((imgs[i].cpu(), labels[i].cpu().item(), preds[i].cpu().item()))\n",
    "        if len(examples) >= 40:\n",
    "            break\n",
    "\n",
    "correct_examples = [e for e in examples if e[1]==e[2]][:8]\n",
    "incorrect_examples = [e for e in examples if e[1]!=e[2]][:8]\n",
    "\n",
    "def show_grid(exs, title):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    for i, (img, label, pred) in enumerate(exs):\n",
    "        plt.subplot(1, len(exs), i+1)\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        plt.title(f'T:{classes[label]}\\nP:{classes[pred]}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "if correct_examples:\n",
    "    show_grid(correct_examples, 'Correct predictions')\n",
    "if incorrect_examples:\n",
    "    show_grid(incorrect_examples, 'Incorrect predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6092c4c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook implements the required MLP and training setup. With `epochs=8` you should typically obtain test accuracy around or above 85% depending on random initialization and whether GPU is used. If accuracy is below 85%, try increasing epochs to 10, or add small changes like weight decay, a learning-rate scheduler, or simple data augmentation."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
